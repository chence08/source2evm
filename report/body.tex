\tableofcontents
\setcounter{secnumdepth}{3}
\newpage
% Chapter 1

%\chapter{Chapter Title Here} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{User-level Documentation}
\textbf{source2evm} is a Source to EVM bytecode compiler written in Typescript. This project comes bundled with standalone EVM binaries for both \code{arm64} and \code{x64} architecture that can be used to execute compiled code.\\\\
The compiler currently supports the compilation of a subset of Source to bytecode for the Ethereum Virtual Machine (EVM). Syntax follows that of Source. 

\subsection{Installation}
\subsection{Installation}
Compiler release can be downloaded from \href{https://github.com/chence08/source2evm/releases/download/v1.0/source2evm_v1.zip}{here} on our \href{https://github.com/chence08/source2evm}{GitHub repository}\\\\
To build: 
\begin{verbatim}
yarn install
yarn tsc
\end{verbatim}

\subsection{Usage}
The compiler can be used through the \code{NodeJS} script \code{source2evm.js}. If executed without compiled compiler code, the script will compile the compiler with \code{tsc}. 
\begin{verbatim}
./source2evm -i [input file] [option]

Options: 
    -r: Execute the code with bundled EVM after compilation. 
    -o: Write output bytecode to output file. 
    -h: Show help message. 
\end{verbatim}

\subsection{Known Issues}
Please switch to Node v14 if there are any issues with running the compiler. Newer versions of Node could cause problems with dependencies. 

\subsection{Supported Features}
\begin{itemize}
  \item Integer arithmetic
  \item Boolean operations
  \item Declaration of variables and constants
  \item Functions
    \begin{itemize}
      \item Function declarations and applications of named and anonymous functions
      \item Nested functions
      \item Recursion, tail call optimisation, mutual recursion
      \item Functions as parameters and return values
    \end{itemize}
  \item Conditionals
    \begin{itemize}
      \item Ternary operator \& if-else statements
    \end{itemize}
  \item While and for loops
    \begin{itemize}
      \item Note that \code{break} and \code{continue} are not supported
    \end{itemize}
\end{itemize}

\subsection{Test cases}
A number of test programs can be found under \code{/tests}. The expected result of evaluation can be found at the end of each file. 

\subsection{Things to note}
\subsubsection{Output}
Similar to the Source interpreter, the compiled code will always return the result of the last statement of the given program that has return results. However, unlike the Source interpreter, if none of the statements in the program have return results, the code will return 0. 
% \\\\
% \textbf{Examples:} \\\\
% \code{
% 3+4; \\
% 2+1; \\
% // output 3 \\
% } \\
% \\
% \code{
% 3+4; \\
% let x = 2+1; \\
% // output 7
% } \\
% \\
% \code{
% let y = 7; \\
% let x = 2+1; \\
% // output 0
% }

\subsubsection{Unused return results}
Due to the compiler's reliance on the EVM's stack for exiting from functions, \textbf{any} unused return values from any statements \textbf{within functions} will cause undefined behaviour, and will likely lead to EVM errors. Such statements can still be used outside of functions.
% \textbf{Examples:}
% \begin{verbatim}
% function f() {
%     3 + 4; // return value 7 not used, will cause EVM error
% return 8;

% function f() {
%     3 + 4; // return value 7 not used,
%           // will not cause EVM error but should still be avoided
% }

% function f() {
%     let x = 3 + 4; // return value 7 is used in assignment
%     return 8;
% }

% 3 + 4; // this is fine as it is not in a function
% function f() { 
%     return 8; 
% }
% \end{verbatim}
\subsubsection{Scoping}
Note that ALL arguments are passed-by-value to functions, hence variables are NOT mutable across function scopes. 
\begin{verbatim}
    let y = 1;
    function f() { y = 2; return 0 };
    y;
\end{verbatim}
The above code will return 1, as \code{f} only changed the value of the copy of \code{y} within its own scope. 
\newpage
\subsection{Compiler Error Messages}
There is no static type checking in the compiler, but the compiler will check and throw exceptions for the following: 
\begin{itemize}
\item Reassigning values to constants
\begin{verbatim}
const x = 2;    x = 3; // reassigning const, compiler will throw exception here
\end{verbatim}
\item Referring to undeclared name
\begin{verbatim}
y + 4; // y not declared, compiler will throw exception here
\end{verbatim}
\item Using an unknown operator
\begin{verbatim}
1 $ 2; // $ is not a supported operator
\end{verbatim}

\end{itemize}
Note that there will not be any line number information in the error messages.
\pagebreak
\section{Developer-level Documentation}
\subsection{Operators}
The following operators are supported: 
\begin{center}
  \begin{tabular}{|c | c | c | c|} 
   \hline
   Operator & Type of operand 1 & Type of operand 2 & Return type \\ 
   \hline\hline
   + & Number & Number & Number \\ 
   \hline
   - & Number & Number & Number \\ 
   \hline
   * & Number & Number & Number \\ 
   \hline
   / & Number & Number & Number \\ 
   \hline
   === & Number/Boolean & Number/Boolean & Boolean \\ 
   \hline
   < & Number & Number & Boolean \\ 
   \hline
   <= & Number & Number & Boolean \\ 
   \hline
   > & Number & Number & Boolean \\ 
   \hline
   >= & Number & Number & Boolean \\ 
   \hline
   \&\& & Boolean & Boolean & Boolean \\ 
   \hline
   || & Boolean & Boolean & Boolean \\ 
   \hline
   ! & Boolean & - & Boolean \\ 
   \hline
  \end{tabular}
\end{center}
The ternary conditional operator is also supported: \\
\code{condition ? if-true : if-false}

When a known number needs to be pushed onto the operand stack, \code{PUSH32} is always used to push it as a 256 bytes integer. \\\\
\begin{prooftree}
    \Hypo{n\rightarrow i}
    \Infer1{n \hookrightarrow PUSH32 \cdot i}
\end{prooftree}\\\\
For most operators with equivalent EVM instructions, the translation is simply a mapping to the equivalent instructions. Note that for operators where the order of the operands matter, e.g. \code{-} and \code{<}, the order in which operands are computed and pushed onto the stack is flipped, where the second operand is pushed first, due to how EVM instructions operate on the stack. \\\\
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 + E_2 \hookrightarrow s_1 s_2 ADD}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 - E_2 \hookrightarrow s_2 s_1 SUB}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 * E_2 \hookrightarrow s_1 s_2 MUL}
\end{prooftree}\\\\\\
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 / E_2 \hookrightarrow s_2 s_1 DIV}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 === E_2 \hookrightarrow s_1 s_2 EQ}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 < E_2 \hookrightarrow s_2 s_1 LT }
\end{prooftree} \\\\\\
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 > E_2 \hookrightarrow s_2 s_1 GT}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 \&\& E_2 \hookrightarrow s_1 s_2 AND}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 || E_2 \hookrightarrow s_2 s_1 OR}
\end{prooftree}\\\\\\
Operators without any equivalents are translated to a combination of instructions. \\\\
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 <= E_2 \hookrightarrow s_1 s_2 EQ \cdot s_2 s_1 LT \cdot OR}
\end{prooftree}\qquad
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Infer2{E_1 >= E_2 \hookrightarrow s_1 s_2 EQ \cdot s_2 s_1 GT \cdot OR}
\end{prooftree}\\\\\\
\code{<=} and \code{>=} operators are simply replicated by replacing them with conjunctions of \code{<} or \code{>} with \code{===}. \\\\
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Infer1{!E_1 \hookrightarrow s_1 ISZERO}
\end{prooftree}\\\\\\
While there is a \code{NOT} instruction in EVM, it is a bitwise \code{not} that inverts all 256 bytes of the input when EVM uses 0 and 1 for false and true respectively, hence to translate \code{!}, we check if the given operand is 0 using the \code{ISZERO} instruction. If a value is 0, it is originally treated as false in EVM, and \code{ISZERO} will return 1, which is true. If a value is any other non-zero value, \code{ISZERO} will return the false value of 0 instead. In either case, \code{ISZERO} returns a boolean value that is the logical negation of the given operand. \\\\\\
\begin{prooftree}
    \Hypo{E_1\hookrightarrow s_1}
    \Hypo{E_2\hookrightarrow s_2}
    \Hypo{E_3\hookrightarrow s_3}
    \Hypo{compile\_conditional(E_1, E_2, E_3)}
\Infer4{E_1 ? E_2 : E_3 \hookrightarrow s_1 \cdot JDEST1\_PC \cdot JUMPI \cdot s_2 \cdot JDEST2\_PC \cdot JUMP \cdot JDEST1 \cdot s_3 \cdot JDEST2 }
\end{prooftree}\\\\\\
Where \code{JUMPI} takes the the top operand on stack as the destination to change \textit{program counter (PC)} to, and jump if the second operand on stack is true. \code{JDEST} is short for \code{JUMPDEST}, the instruction that adds a label for jump destinations. Each \code{JDEST} in the above proof tree is labelled with a number behind for clarity. \code{JDESTi\_PC} refers to the PC location of the corresponding \code{JUMPDEST} to be used as destination for \code{JUMP} and \code{JUMPI} instructions. They are calculated at runtime by first putting current PC on stack with the \code{PC} instruction, then adding the PC distance from that point to the destination, which is calculated during compilation. 

\subsection{Conditionals}
The ternary conditional operator is documented above. Conditional expressions in the form 
\begin{verbatim}
if (cond) {
    // if true
} else {
    // if false
}
\end{verbatim}
are first converted to the ternary operator form, then their condition expression, truth expression, and false expression are extracted to be passed to the \code{compile\_conditional} function to be compiled in the same way as the ternary operator version. \\\\
\begin{prooftree}
    \Hypo{\texttt{if}\ (E_1)\ \{E_1\}\ \texttt{else}\ \{E_3\}}
    \Infer1{E_1 \texttt{?} E_2 \texttt{:} E_3}
\end{prooftree}\\\\
For if-else form of conditionals, the expressions within curly braces do not have their own independent scope. 

\subsection{Memory model}
EVM does not have registers or a conventional runtime stack, hence we have decided to use the memory to simulate both a runtime stack and shared registers. \\\\
We have allocated the memory from 0x40 to 0x200 for stack frame pointers, and addresses from 0x220 onward are used for the call stack. Each stack frame on the call stack will contain values for all names that environment, which may either be a function or the main scope, contains within its lexical scope. As all names are allocated an address at the point of initialisation of that environment, which, for this compiler, would be at the during initialisation of functions. \\\\
To keep track of the current active stack frame, addresses 0x00 and 0x20 are used as registers. 0x00 always contains the address of the current stack frame pointer, i.e. the stack frame pointers stored from 0x20 to 0x200. 0x20 will always store the actual address of the current stack frame, i.e. the value held at the address 0x00 points to. \\\\
The stack frame pointers each point to the start of its corresponding stack frame. As the stack grows downwards, more stack frame pointer entries are placed onto the stack frame pointer stack, growing it with the call stack. For both the call stack and the stack frame pointer stack, the next available address is the one that immediately follows the current active stack frame. For the stack frame pointers, the next pointer will be pushed to the address of the current stack frame pointer plus 0x20. For the stack frame itself, the next available address will be the start of the current stack frame offset by the number of variables it contains times 0x20. \\\\
When a function returns and the stack frame is no longer needed, the exiting stack frame will be "popped" by pointing the active stack frame pointer to the previous stack frame, "moving up" in both the stack frame pointer stack and the call stack. When another function is called, it's stack frame will start from the address previously used by the exited function, overwriting the previous memory. Garbage collection is thus not needed as memory is implicitly reclaimed upon function exit. 
\subsubsection{Variables}
During compilation, the compiler keeps a lookup table of the names known to each environment under \code{closure\_lookup.locals} in the compiler, and each name is given an offset amount, starting from 0x20, and increasing by 0x20 with every name. These names are the variables that the program can access in that environment. To access a variable, EVM takes the value at 0x20, then adds the offset for that variable name, which was determined at compile time, to obtain the actual address that variable resides at, where it can then invoke \code{MLOAD} or \code{MSTORE} to read from or write to that variable. \\

\subsection{Loops}
Loops carry their own closures. Two jump destinations are created during compilation, one before the condition and one at the very end of the loop, before the start of the rest of the program. \texttt{JUMPI} is invoked to send the PC to the loop body, otherwise if the condition is not truthy, the PC will skip outside the loop.
\subsubsection{While Loops}
\begin{verbatim}
while (cond) {
    // body
}
\end{verbatim}
\subsubsection{For Loops}
\begin{verbatim}
for (let i = 0; i < 0; i = i+1) {
    // body
}
\end{verbatim}
For loops have an additional three-part sequence that also exist within the loop's closure. A minor tweak would be to treat the \textbf{updating statement} as part of the loop body, the \textbf{test statement} as the loop condition, and be very careful to exclude the \textbf{initialisation statement} during the jump.
\subsection{Functions}
Functions exist in two forms, the code compiled from their body, and the PC offset serving as entry points to jump to. Within the final compiled bytecode, the bytecodes for all functions, named or anonymous, are placed at the start. The PC offsets for each function is thus known at compile. During runtime, the named functions are treated in the same way as other constant variables, only that the value stored in memory for a function is its PC offset. This allows functions to be passed as parameters and returned as return values just like any other data. 
\subsubsection{Function definition}
Functions can be defined in two ways, either through a function declaration: 
\begin{verbatim}
function f(arg) {
    // function body
}
\end{verbatim}
or through a constant declaration of a lambda expression: 
\begin{verbatim}
const f = arg => {
    // function body
}
// or: 
const f = arg => return statement
\end{verbatim}
The function declaration form will be transformed to the constant declaration form. The constant declaration will be passed to the \code{compile\_constant} function, which will extract the constant name, in this case the function name, and pass the lambda expression to the \code{compile\_lambda\_expression} function for code generation. The compiled bytecode for all functions will be placed near the start of the final compiled program. \code{compile\_constant} will, in the case of functions, return the bytecode for pushing the PC offset, which is known at compile time since it is just the number of bytes from the start of the compiled program, for the \code{JUMPDEST} of the function entry. During runtime, this PC offset will be stored into the address allocated in the stack frame for that function name. When that name is accessed like any other names, the PC offset will be retrieved, which EVM will call \code{JUMP} on to enter the function.
\newpage
\code{compile\_lambda\_expression} will construct the compiled code in three parts: 
\begin{itemize}
    \item \textit{Read and store arguments}: This is the first part of the function code that is ran when the function code is accessed. Since the function code is only accessed during application, it is assumed that before the jump, the application in caller has already placed all required arguments for the function call on the operand stack. For every argument the function has, \code{compile\_lambda\_expression} will generate bytecode that takes the top element on operand stack, and stores it in memory, based on the stack frame offset for the argument name, determined at this stage based on its order of appearance in the given code, and the stack frame address, determined at runtime. \code{compile\_lambda\_expression} will also record names and assign offsets for all locally declared names in the compiler lookup table. 
    \begin{itemize}
        \item Note that compiler will scan for all free variables in the function and in all its nested functions, and these variable names will be added appended to the list of arguments. The original arguments will be read and stored first, followed by the free variables. 
        \item Original arguments are assigned offsets first, followed by free variables, then locally bound variables. 
        \item During application, input arguments are pushed to stack in the order that they are given, hence the last argument will be the first value on stack, so arguments are read from stack in reverse order. 
    \end{itemize}
    \item \textit{Function body}: This is the main body of the function. The body of the function is extracted and passed to \code{compile\_expression} with the updated lookup. The returned result will be the bytecode containing the main logic of the function. 
    \item \textit{Stack frame and PC updates} Every function application creates a new stack frame during runtime, and moves back to the caller's stack frame upon function exit, hence code for updating runtime stack at both the start and end of the compile function bytecode is needed. After the function is fully executed, PC also needs to be restored to after the \code{JUMP} invoked by function application. 
        \begin{itemize}
            \item Return PC is pushed on stack before arguments are pushed during function call. We expect functions to always have a single return value that is the result of the final statement executed in the function or a return statement. When the function is ready to return, the top two elements on operand stack should be \textit{return value} and \textit{return PC}. \code{SWAP1} and \code{JUMP} are then called in that sequence to jump to return PC and leave return value on top of the stack.
            \begin{itemize}
                \item This approach is the reason for statements with unused return values to result in unexpected behaviours that would most like cause jump errors in EVM, as the presence of additional values on operand stack causes return \code{JUMP} to not jump to the correct PC. 
            \end{itemize}
        \end{itemize}
\end{itemize}
\newpage
The code generated for a function thus follows the following structure: 
\begin{center}
\begin{tabular}{ |c| } 
 \hline
 Jump Destination \\
 \hline
 Create new stack frame and update pointers to runtime stack \\
 \hline
 Get and store arguments from operand stack \\
 \hline
 Function body \\
 \hline
 Return to previous stack frame \\
 \hline
 \code{SWAP1} and \code{JUMP} to jump back to caller \\
 \hline
\end{tabular}
\end{center}

\subsubsection{Function application}
When a function is applied, e.g. \code{f(1, 2, 3)}, the return PC is first calculated by calling the instruction \code{PC}, then adding the distance from there to 1 byte after the \code{JUMP} instruction used to enter the function. This puts return PC on stack, allowing PC to be set to the instruction that immediately follows the function application. \\\\
This section will only cover application of named functions, application of anonymous functions will be covered later. \\\\
When there is a function application, the compiler generates code for the application in the following steps: 
\begin{itemize}
    \item \textit{Prepare captured variables}: compiler will retrieve list of captured variables from the lookup, then searches for them within the current scope, and generate code that load them from memory, pushing them onto stack. 
    \item \textit{Prepare arguments}: the actual list of arguments will now be compiled, which will result in their values being pushed on top of the operand stack at the end. 
    \item \textit{Get PC offset of function to be called}: compiler generates code that will retrieve, from memory, the PC offset of the function to be called. Such offsets are stored in memory like any other variables. 
    \item \textit{Prepare jump and return PC}: compiler will then append \code{JUMP}, code for returning stack frame, and \code{JUMPDEST} for the actual entry to function and eventual return. With the length of the code known now, the return PC can be calculated with \code{Current PC + length(code) + 1}. The return PC will be pushed on to stack first to put it below function arguments. 
        \begin{itemize}
            \item If the returned expression is a function, the function's free variables will be first pushed on to the operand stack before \code{JUMP} is called. The application of functions that return functions thus have to be followed by another application immediately to consume the function returned by calling \code{JUMP} with the returned function PC on the stack. 
        \end{itemize}
\end{itemize}
\begin{table}[!h]
\begin{center}
\begin{tabular}{ |c| } 
 \hline
 Function PC \\
 \hline
 Function arguments \\
 \vdots \\
 \hline
 Function captures \\
 \vdots \\
 \hline
 Return PC \\
 \hline
\end{tabular}
\caption*{Stack at the point of \code{JUMP}}
\end{center}
\end{table}
\newpage
\subsubsection{Variable capture}
Instead of extending the current closure to capture variables from outer scopes, this compiler extends the list of arguments instead. The function \code{scan\_out\_names} scans out all names in a given parse tree that are \textit{not} locally declared or, in the case of functions, one of the function arguments. This scanning is done at the start of a sequence of expressions before any functions are actually compiled using the \code{scan\_out\_names} function through DFS of the entire parse tree. The resultant list of list of captured variables for each function is stored in the lookup table under \code{funcs}, with each list mapped to the name of the function it came from. This list is referred to when compiling both lambda expressions and applications.\\\\
In addition to free variables, the name of the applied function is also added as a parameter. This is to allow for nested recursions like the following to be possible. 
\begin{center}
\begin{verbatim}
function f() {
    return g();
}
function g() {
    return f();
}
\end{verbatim}
\end{center}

\subsubsection{Tail call optimisation}
For functions whose return expression consists of only a function application, the compiler compiles the return differently through the \code{compile\_tail\_call\_recursion} function. During runtime, this application will first pop the current stack frame before entering the new function, which generates another frame. 

\subsubsection{Anonymous Functions}
Anonymous functions are defined when they are applied, or as return results (in which case they need to be applied immediately after being returned). They are thus compiled during application. When compiling a return expression or application and the expression is a lambda expression, they are compiled as lambda expressions and have their free variables scanned at that moment. Their PC offset is not stored in memory as it is only used once. They behave similarly to named functions other than when they are compiled. 

% \subsection{Garbage Collection}

% Garbage collection is implicitly implemented in our compiler design.\\\\
% Testament:
% \begin{itemize}
% 	\item For loop that calls a function that creates a bunch of variables. Each function call creates a new Environment, but the heap (memory) size will stay relatively constant
% 	\begin{verbatim}
% 		function f() {
% 		    let x = 5;
% 		    let y = 6;
% 		}
% 		for (let i = 0; i < 3; i = i + 1) {
% 		    f();
% 		}
% 	\end{verbatim}
% 	\item tail\_recursion would take up constant space in the heap.
% \end{itemize}

\newpage
\subsection{Compiler functions}
\subsubsection{\texttt{compile\_expression}}
Applies the appropriate compiler function depending the type of expression. \\\\
\begin{prooftree}
    \Hypo{E}
    \Infer1{E\hookrightarrow s}
\end{prooftree}
\subsubsection{\texttt{compile\_sequence}}
This function takes a sequence of expressions and does two things: \\\\
\textbf{Convert free variables in each function to arguments}
\begin{enumerate}
    \item Scans out all functions in the program through DFS
    \item For each function, retrieve name and scan out all free variables, including those in nested functions
    \item Store, in \code{closure\_lookup.funcs}, the function name to captured variable pairs, pushing in the name of the function itself
\end{enumerate}
\textbf{Compiles every expression in the sequence by applying \code{compile\_expression}}\\\\
\begin{prooftree}
    \Hypo{E_1 \hookrightarrow s_1, ..., E_n \hookrightarrow s_n}
    \Infer1{\{E_1, ..., E_n\} \hookrightarrow s_1...s_n}
\end{prooftree}
\subsubsection{\texttt{compile\_constant}}
\begin{enumerate}
    \item Get constant name
    \item Record name in \code{closure\_lookup.locals}
    \item Add name to in \code{closure\_lookup.constants}
    \item If is a function, call \code{compile\_lambda\_expressions}
    \item Generate code for pushing value (or function PC offset) to operand stack and storing in appropriate location
\end{enumerate}
\subsubsection{\texttt{compile\_conditional}}
\begin{prooftree}
    \hypo{E}
    \hypo{E_1}
    \hypo{E_2}
    \infer3{E\ ?\ E_1:E_2}
\end{prooftree}\qquad
\begin{prooftree}
    \hypo{\Delta\Vdash E\rightarrowtail true}
    \hypo{\Delta\Vdash E_1\rightarrowtail v_1}
    \infer2{\Delta\Vdash E\ ?\ E_1:E_2\rightarrowtail v_1}
\end{prooftree}\qquad
\begin{prooftree}
    \hypo{\Delta\Vdash E\rightarrowtail false}
    \hypo{\Delta\Vdash E_2\rightarrowtail v_2}
    \infer2{\Delta\Vdash E\ ?\ E_1:E_2\rightarrowtail v_2}
\end{prooftree}

\subsubsection{\texttt{compile\_while\_loop}}
Creates a \texttt{new\_env} that extends from its enclosing environment. All statements within the loop operate as per usual through \texttt{compile\_expression} within \texttt{new\_env}. PC offsets are generated on compile time to demarcate the start of condition checking and end of loop, respectively.

\subsubsection{\texttt{compile\_for\_loop}}
Same as while loop, except for special jump instructions to accommodate the three-part initialization sequence.

\subsubsection{\texttt{compile\_lambda\_expression}}
Generates code as follows: \\\\
\textbf{Allocate space on stack and consume arguments on operand stack}\\\\
\begin{prooftree}
    \Hypo{(x_1, ..., x_n, v_1, ..., v_m) => \{E\}}
    \Infer1{(x_1, ..., x_i, ..., x_n, v_1, ..., v_m) \hookrightarrow (PUSH4\cdot 32i \cdot PUSH \cdot 0x20 \cdot ADD \cdot MSTORE)^{(n+m)}}
\end{prooftree}\\\\\\
where $x^{(n)}:=x$ is repeated $n$ times\\\\
\textbf{Compile lambda body}\\\\
\begin{prooftree}
    \Hypo{E \hookrightarrow s}
    \Infer1{(x_1, ..., x_i, ..., x_n, v_1, ..., v_m) => {E} \hookrightarrow s}
\end{prooftree}\\\\\\
\textbf{Return PC}\\\\
\begin{prooftree}
    \Infer0{SWAP1 \cdot JUMP}
\end{prooftree}\\\\
The resultant chunks of code are concatenated together, prepended with \code{JUMPDEST}, and appended to the global variable \code{constants}. The code for storing PC offset of this function to memory is returned.  

\subsubsection{\texttt{compile\_application}}
\begin{enumerate}
    \item Calculate return PC and push onto operand stack
    \item Compile arguments and captured variables\\\\
    \begin{prooftree}
        \Hypo{E_1 \hookrightarrow s_1, ..., E_n \hookrightarrow s_n, v_1 \hookrightarrow c_1, ..., v_m \hookrightarrow c_m}
        \Infer1{(E_1, ..., E_n, v_1, ..., v_m) \hookrightarrow s_1 ... s_n v_1...v_m}
    \end{prooftree}, \\\\where $v_i$ are captured variables of the function. 
    \item Generate code to retrieve function offset
    \item Append \code{JUMP} and \code{JUMPDEST}
\end{enumerate}

\subsubsection{\texttt{compile\_tail\_call\_recursion}}
After computing arguments and pushing them onto stack, retrieve PC offset for applied function, then pop current stack frame before pushing return PC and calling \code{JUMP}. 

\subsection{Known Issues}
\begin{enumerate}
    \item Loops cannot accommodate function calls within its scope as the PC offsets of the function block is not easily obtainable through the existing implementation. Better pre-processing of functions and loops would certainly resolve this issue.
\end{enumerate}